---
title: "ggplot2 extras"
author: "Martin Frigaard"
date: "9/8/2017"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(magrittr)
library(mosaic)
library(skimr)
# create image folder ----
if (!file.exists("images/")) {
    dir.create("images/")
}
# create data folder ----
if (!file.exists("data/")) {
    dir.create("data/")
}
# knitr settings ------
knitr::opts_chunk$set(
    echo = TRUE, # show all code
    tidy = FALSE, # cleaner code printing
    size = "small",
    fig.path = "images/") # smaller code
knitr::opts_knit$set(
    width = 78)
base::options(tibble.print_max = 25,
              tibble.width = 78)
```


# Loading the packages 

```{r sessionInfo, message=FALSE, warning=FALSE, echo=FALSE}
# fs::dir_ls("code/R")
source("code/R/load_packages.R")
```

First, load the `tidyverse`.

```{r packages}
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(magrittr)))
```

The [`tidyverse`](http://tidyverse.org/) is a collection of R packages developed by RStudio's Chief Scientist [Hadley Wickham](http://hadley.nz/). These packages work well together as part of larger data analysis pipeline. To learn more about these tools and how they work together, read [R for data science](http://r4ds.had.co.nz/). 

![the tidyverse](https://raw.githubusercontent.com/mjfrigaard/storybenchR/master/images/tidyverse2.1.png)

We will be using the `bad_drivers` data set from ["Dear Mona, Which State Has The Worst Drivers?"](http://fivethirtyeight.com/datalab/which-state-has-the-worst-drivers/). We load it into out working environment and give it a `_df` to identify that this object is the data frame.


```{r police_locals}
bad_drivers_df <- fivethirtyeight::bad_drivers
bad_drivers_df %>% glimpse()
```

### The aesthetic mapping 

The aesthetic is the part of the graph we see. When we apply a numerical value (or variable) to an aesthetic, we refer to this as **mapping**. Consider the call below in which we map `perc_speeding` to `insurance_premiums` to the x and y. We assign this to a new object and add `_aes` to remind us this is the data frame and aesthetic mapping.   

```{r aes}
bad_drivers_df_aes <- bad_drivers_df %>% ggplot(aes(x = perc_speeding, y = insurance_premiums))
bad_drivers_df_aes
```

This creates a blank canvas (or carteisn coordinate system) with the two mapped variables (`perc_speeding` and `insurance_premiums`), but we don't see any data points. These are added in the next layers. 

### the stat and geom

We would like to see the scatter plot between these two variables, but in order to do that we need to understand something about the statistical transformations and geometric objects. Every geometric object has belongs to a particular statistical transformation, and every statistical transformation has a particular geometric object. 

We can get under the hood of these functions by looking at the `layer` function.

```{r}
p <- ggplot(data = diamonds, mapping = aes(x = carat))
p2 <- p + layer(
    geom = "bar",
    params = list(binwidth = 0.5, 
                  fill = "white", 
                  color = "steelblue"),
    stat = "bin",
    position = "identity")
p2
```


```{r}
bad_drivers_df_aes + layer(
     mapping = NULL, # already specified
     data = NULL, # already specified
     geom = "point",
     stat = "identity",
     position = "identity")
```

We can see `"point"` is the `geom` for a scatter plot, and that `"identity"` (which leaves the data unchanged) is the default `stat` and `position`. But we can lesson the typing by just using the shortcut `geom_point()`. 

```{r}
bad_drivers_df_aes_stat_geom <- bad_drivers_df_aes + geom_point()
bad_drivers_df_aes_stat_geom
```

### the position

The `position` argument adjusts the geometric objects to provide a clearer image. For example, I can add `geom_jitter()` to add some random noise to every data point. We will call this object `gg_bad_drivers` because it has all five layers. 

```{r}
gg_bad_drivers <- bad_drivers_df_aes_stat_geom +
     geom_jitter(width = 10, height = 10)
gg_bad_drivers
```

This makes more sense when we are dealing with categorical or discrete values and many data points overlap. 

## Adding the layers

Now that we have the basics down, we can start adding more layers to build better graphs. 

Lets look at the relationship between `perc_alcohol` (the percentage of drivers involved in fatal collisions who were alcohol-impaired) and `losses` (financial losses incurred by insurance companies for collisions per insured driver), but add the color aesthetic.   

```{r}
bad_drivers_df %>% ggplot(aes(x = perc_alcohol, y = losses)) + 
                   geom_point(aes(color = state)) 
```

The legend makes the plot hard to see, so I will use the `theme(legend.position = "none")` function to remove the legend altogether. 

```{r}
bad_drivers_df %>% ggplot(aes(x = perc_alcohol, y = losses)) + 
                   geom_point(aes(color = state)) + 
                   theme(legend.position = "none")
```

That's better. But I want to the point to represent the number of `num_drives` (the number of drivers involved in fatal collisions per billion miles).

```{r}
bad_drivers_df %>% ggplot(aes(x = perc_alcohol, y = losses)) + 
                   geom_point(aes(color = state, size = num_drivers)) + 
                   theme(legend.position = "none")
```

It's a little hard to tell which state is which without labels, so I'll add a `geom_text` and apply the `size` of the text to `num_drivers`.

```{r}
bad_drivers_df %>% ggplot(aes(x = perc_alcohol, y = losses)) + 
                   geom_point(aes(color = state)) + 
                   geom_text(aes(label = state, color = state, size = num_drivers)) +
                   theme(legend.position = "none")
```

## Adding region

Lets break this down further by region. Below are vectors for each US state region. 

```{r american_midwest}
american_midwest <- c("Illinois", "Indiana", "Iowa", "Kansas", "Michigan", "Minnesota", "Missouri", "Nebraska", "North Dakota", "Ohio", "South Dakota", "Wisconsin")
american_northeast <- c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont", "New Jersey", "New York", "Pennsylvania")
american_south <- c("Delaware", "Florida", "Georgia", "Maryland", "North Carolina", "South Carolina", "Virginia", "District of Columbia", "West Virginia", "Alabama", "Kentucky", "Mississippi", "Tennessee", "Arkansas", "Louisiana", "Oklahoma", "Texas")
american_west <- c("Arizona", "Colorado", "Idaho", "Montana", "Nevada", "New Mexico", "Utah", "Wyoming", "Alaska", "California", "Hawaii", "Oregon", "Washington")
```

I want to create a new variable `region`, in the `bad_drivers_df` data frame, and then `facet` the graphs according to this new variable. 

Let's do this is one pipeline

```{r case_when_pipeline}
bad_drivers_df %>% 
mutate(
     region = 
          case_when(
               state %in% american_midwest ~ "midwest",
               state %in% american_northeast ~ "northeast",
               state %in% american_south ~ "south",
               state %in% american_west ~ "west", 
               TRUE                      ~  "other")) %>% 
                    ggplot(aes(x = perc_alcohol, y = losses)) + 
                    geom_point(aes(color = region, size = num_drivers)) +
                    geom_text(aes(label = state, size = 8)) + 
                    facet_grid(. ~ region) 
```

This graph combines the positions, colors, size, labels, and facets to display the relationship between the amount of money lost by insurance companies for collisions per insured driver and the percentage of alcohol-impaired drivers involved in fatal collisions. 

```{r babynames}
library(babynames)
```




Now that we know the basics for a `ggplot2` graph, we can start to build on these foundations to get more interesting representations of the data. 




We will start with the native `diamonds` data set from the `ggplot2` package. 

```{r ingest}
# put the diamonds data set into its own data frame
dmnds_gg <- ggplot2::diamonds
```

I use `gg` for data sets I create visualizations with (for pattern matching purposes).

```{r inspect}
dmnds_gg %>% glimpse()
```

We will start by breaking down the components of a basic `ggplot` call. Before we do this, I want to get some basic summary statistics for `price` and `carat`. 

```{r carat_sum}
knitr::kable(
dmnds_gg %>% 
     dplyr::select(carat) %>% 
     summarise(
          min_carat = min(carat),
          max_carat = max(carat),
          med_carat = median(carat),
          mean_carat = mean(carat))
)
```

**NOTE:** Makes tables pretty using `knitr::kable()`


```{r price_sum}
knitr::kable(
dmnds_gg %>% 
     dplyr::select(price) %>% 
     summarise(
          min_price = min(price),
          max_price = max(price),
          med_price = median(price),
          mean_price = mean(price))
)
```

Ok now that we have an idea for each of these variables individually, lets see how they looks in a graph plotted against each other. 

```{r}
dmnds_gg %>% ggplot( 
               aes(  
                 x = carat, 
                 y = price)) + 
                   geom_point() 
```

What do we see? This graph looks like a scatter plot between `price` and `caret`. There seems to be a pattern in this relationship (which we will discuss more later), but is this what we would expect to see?



## the geoms

We tend to think of graphics and visualizations in terms of the shapes we see (i.e. the dots, bars, lines, etc.). The `ggplot()` function creates plots in R conveniently named after these **geometric objects** using a `geom_` (i.e. `geom_bar` for bar charts, `geom_line` for line charts, etc). Each `geom_` argument has five components:

1. `data`: the data set (`diamonds`)     
2. `mapping`: horizontal (`x`) position = `carat`, vertical (`y`) position = `price`       
3. `geom`: geometric objects like scatter plots, histograms, lines, etc. = `point`      
4. `stat`:  statistical transformations (i.e. counts or bins) = `identity`for raw data     
5. `position`: adjusting any overlapping objects = `identity`for raw data       

The grammar allows us to build a plot with each component explicitly using the `layer` function (and the native `diamonds` data set). 

##### Why the crazy indentations?   

I like to capitalize on English's flat branching structure, because each clause (graph component) ends up on it's own line, and the entire graph command can extended diagonally with commas(`,`). I don't always remember to arrange it this way, but it helps when I am building a plot or trying to read someone else's.

```{r}
ggplot() +
    layer(
    data = diamonds,                       # 1 THE DATA SET
            mapping = aes(                 # 2 MAPPINGS
                x = carat,                 # x axis 
                y = price),                # y axis 
                    geom = "point",        # 3 GEOM_FUNCTION
                    stat = "identity",     # 4 STAT
                    position = "identity") # 5 POSITION
```




The reason we don't have to state each part explicitly is the beauty of the `ggplot2` package. The grammar comes loaded with smart defaults for many of the graph components, so we don't have to remember what `stat` goes with each `geom`. 

There are actually seven parts to each `ggplot2` graph, although not all are required. We will explore the other functions later. A template for the grammar is available below:

```r
ggplot(data = <THE DATA SET>) + # default data and aesthetic mapping 
 geom_<GEOM_FUNCTION>( # the geometric object
  mapping = aes(<MAPPINGS>), # map aesthetics (with scales)
  stat = <STAT>, # statistical transformations
  position = <POSITION> # position adjustments
  ) +
  <COORDINATE_FUNCTION> + # coordinate systems
  <FACET_FUNCTION> # facets 
```

It's also available [here](http://r4ds.had.co.nz/data-visualisation.html#the-layered-grammar-of-graphics)

***

For additional `tidyr` functions using `qplot`, we will use the data for the story "*A Statistical Analysis of the Work of Bob Ross*", available [here](http://fivethirtyeight.com/features/a-statistical-analysis-of-the-work-of-bob-ross/). Let's load it in and take a look. 

```{r bob_ross}
bob_gg <- fivethirtyeight::bob_ross
bob_gg %>% glimpse()
```

Ugh--what **IS** this? Well, this is a standard *binary format* data set, with each variable telling us the presence (`1`) or absence (`0`) of each variable. 

***NOTE***: if you are ever creating binary variables, always have `1` equal the presence of the variable name, and `0` coded as the absence. For example, a binary `gender` variable could be named `male`, and `1` could be the numerical code for male gender (this also helps with sorting because the character variable will sort `female` before `male`, which aligns with the `0` and `1`). Developing these habits early (and sticking to them!) makes your analyses more organized and easy to follow. 

We will convert this format into a [tidy]() data set.

```{r bob_tidy_gg}
bob_tidy_gg <- bob_gg %>%
  gather(object, present, -c(episode, season, episode_num, title)) %>%
  mutate(present = as.logical(present)) %>%
  arrange(episode, object)
bob_tidy_gg %>% glimpse()
```

The `ggplot2` package (and all others in the `tidyverse`) work best with tidy data. If you are ever curious if your data is tidy, consider it's structure and measurements. The original `bob_ross` data set had 403 observations and 71 variables. This new `bob_tidy_gg` has 27,001 observations and 6 variables. That's because the original `bob_ross` data set had variables for every item his paintings, and whether it was there (or not). This doesn't meet the tidy rule of one variable per column, because these columns are actually representing a measurement of painting `object`s, and whether the object is `present` or not. In this case, we prefer the data structure that contains the most *granular measurement variables*.   

```{r celeb_heights}
# fs::dir_ls("data")
celeb_heights <- read_csv("data/celeb_heights.csv")
celeb_heights %>% 
    dplyr::glimpse()
```


For example, let's say I want to look at the relationship in `child` and `parent` heights in the `HistData::PearsonLee` dataset. This data set is a little different than most because it has a `frequency` variable. 

```{r HistData, message=FALSE, warning=FALSE}
library(HistData)
hts_df <-  PearsonLee %>% tbl_df
hts_df %>% 
     ggplot(aes(x = parent, y = child)) +
     geom_point()
```




```{r NHANES}
library(NHANES)
nhanes <- NHANES::NHANES
```


```{r}
knitr::kable(
favstats(nhanes$Weight)
)
```

Get the summary for `Weight`.

```{r}
knitr::kable(
favstats(nhanes$Height)
)
```

Now with a little bit of summary info I can start to imagine what this scatter plot will look like. First, my `x` and `y` scales will go from `2.8` - `230.7` and `83.6` - `200.4`. I also know that most of the data (dots) will be around `70` for weight and `160` for height. Does this tell me if the relationship between them is linear?


If this is a linear relationship, **I should expect to see a bunch of dots grouped together on the diagonal (lower-left to upper-right)**. I am going to create a scatter plot with these two variables, but first I am going to filter out the missing `Height` and `Weight` values.

```{r scatter}
nhanes %>% 
  filter(!is.na(Weight) & !is.na(Height)) %>% 
  ggplot(aes(x = Weight, y = Height)) + 
    geom_point() 
```

The relationship between these variables looks fairly linear (i.e. diagonal), but it also seems to have a bit of a curve. We also have a fair amount of overplotting (points sitting on top of one another). We can clean this up in a couple different ways. The first is to impose a `size` value in the `geom_point()`. 

```{r size}
nhanes %>% 
  filter(!is.na(Weight) & !is.na(Height)) %>% 
  ggplot(aes(x = Weight, y = Height)) + 
    geom_point(size = 0.6) 
```

The `size` argument is in reference to the size of the points. We could also change the tranparency of the points using the `alpha` aesthetic.

```{r}
nhanes %>% 
  filter(!is.na(Weight) & !is.na(Height)) %>% 
  ggplot(aes(x = Weight, y = Height)) + 
    geom_point(alpha = 1/10)
```

Finally, we could also not use all of the data (i.e. take a random sample of `50` observations from the `nhanes` data set)

```{r random_sample}
nhanes %>% 
     sample_n(size = 500) %>% 
          filter(!is.na(Weight) & !is.na(Height)) %>% 
               ggplot(aes(x = Weight, y = Height)) + 
                    geom_point()
```

All of these solutions work, but I would use the `size` or `alpha` options because we don't have to choose how many observations to keep. 

So does this relationship look linear? We can use the `geom_smooth()` function to see what line best fits these data. We'll reduce the tranparency to `1/10` for clarity, too. 

```{r geom_smooth}
nhanes %>% 
  filter(!is.na(Weight) & !is.na(Height)) %>% 
  ggplot(aes(x = Weight, y = Height)) + 
    geom_point(alpha = 1/10) + 
     geom_smooth()
```

It looks like the `geom_smooth()` function fit a line using `method = "gam"`, and not `method = "lm"`. This is another default in `ggplot2`--plots with 1000+ observations use the `"gam"` method. We can specify the linear method by simply adding another `geom_smooth()`, but we should make sure to specify a different line color (`color = "red"`).

```{r 2x_geom_smooth}
nhanes %>% 
  filter(!is.na(Weight) & !is.na(Height)) %>% 
  ggplot(aes(x = Weight, y = Height)) + 
    geom_point(alpha = 1/10) + 
     geom_smooth() +
     geom_smooth(method = "lm", color = "red")
```
***NOTE***: the `alpha` aesthetic can take fractions (`1/10`) or decimals (`0.1`).

Scatter plots (`geom_point()`) are a great way to show the relationship data from two continuous variables. But what if you want to look at how a continuous variable is distributed across the levels of a categorical (or factor) variable? There is more than one way to do this, but we will start with a stacked bar chart.

### Stacked bar charts

I want to know how the variable `Age` varies across `Gender` in the `nhanes` data set. I can get some quick summary statistics by using `group_by` from `dplyr`: 
```{r}
nhanes %>% 
     group_by(Gender) %>% 
     summarise(
          min = min(Age),
          max = max(Age),
          median = median(Age),
          mean = mean(Age),
          Mode = mode(Age))
```

Ok my summary statistics let me know that I should be expecting a graph that ranges from `0` to `80` on the `x`. Can we tell what the most common age is? The statistical term for this is the **mode**, and unfortunately R doesn't have a quick and easy way to get the mode for variables in data frames. No problem though

```{r}
my_mode <- function(x, na.rm = FALSE) {
  if (na.rm) {
    x = x[!is.na(x)]
  }
  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}
```



```{r}
nhanes %>% 
     group_by(Gender) %>% 
     summarise(
          min = min(Age),
          max = max(Age),
          median = median(Age),
          mean = mean(Age),
          mode = my_mode(Age))
```



A stacked bar chart uses the `fill` aesthetic to separate the levels of a categorical or factor variable by color. 

```{r}
nhanes %>%
     ggplot(aes(x = Age, fill = Gender)) +
          geom_bar()
```

The `y` axis is a count of number of observations in each bar. `ggplot2` also automatically provides a legend to keep track of each level. 



This was a very brief tutorial of the `ggplot2` package, so I recommend learning more about the package by typing `library(help = "ggplot2")` into your R console, checking out the [ggplot2](http://ggplot2.tidyverse.org/reference/ggplot2-package.html) tidyverse page, or purchasing the [ggplot2 book](https://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/331924275X/ref=sr_1_1?s=books&ie=UTF8&qid=1504615645&sr=1-1&keywords=ggplot2). 
