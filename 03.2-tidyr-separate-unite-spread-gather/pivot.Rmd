---
title: "Pivoting"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Pivoting}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_max = 10)
```

# Introduction

This vignette describes the use of the new `pivot_longer()` and `pivot_wider()` functions. Their goal is to improve the usability of `gather()` and `spread()`, and incorporate state-of-art features found in other packages.

For some time, it's been obvious that there is something fundamentally wrong with the design of `spread()` and `gather()`. Many people don't find the names intuitive and find it hard to remember which direction corresponds to spreading and which to gathering. It also seems surprisingly hard to remember the arguments to these functions, meaning that many people (including me!) have to consult the documentation every time.

There are two important new features inspired by other R packages that have been advancing of reshaping in R:

* The reshaping operation can be specified with a data frame that describes 
  precisely how metadata stored in column names becomes data variables (and 
  vice versa). This is inspired by the [cdata][cdata] package by John Mount and 
  Nina Zumel. For simple uses of `pivot_longer()` and `pivot_wider()`, this 
  specification is implicit, but for more complex cases it is useful to make 
  it explicit, and operate on the specification data frame using dplyr and 
  tidyr.
  
* `pivot_longer()` can work with multiple value variables that may have 
  different types. This is inspired by the enhanced `melt()` and `dcast()` 
  functions provided by the [data.table][data.table] package by Matt Dowle and
  Arun Srinivasan.

In this vignette, you'll learn the key ideas behind `pivot_longer()` and `pivot_wider()` as you see them used to solve a variety of data reshaping challenges from simple to complex.

To begin we'll load some needed packages. In real analysis code, I'd expect many people will do this with `library(tidyverse)`.

```{r setup, message = FALSE}
library(tidyr)
library(dplyr)
library(readr)
```

# Wide to long

`pivot_longer()` makes datasets __longer__ by reducing the number of columns and increasing the number of rows. `pivot_longer()` is commonly needed to tidy wild-caught datasets as they often optimise for ease of data entry or ease of comparison rather than ease of analysis. 

## Simple pivoting {#pew}

The `pew` dataset stores count from a survey which (among other things) asked people about their religion and annual income:

```{r}
pew <- read_csv("pew.csv", col_types = list())
pew
```

This is 2d table with religion in the rows, income spread across the column names, and a count stored in the cell values. To tidy it we need `pivot_longer()`:

```{r}
pew %>% 
  pivot_longer(cols = -religion, names_to = "income", values_to = "count")
```

* The first argument describes which columns need to be transformed. 
  In this case, it's every column apart from `religion`.

* The `names_to` gives the name of the variable that will be created from
  the data stored in the column names.
  
* The `values_to` gives the name of the variable that will be created from
  the data stored in the cell values.
  
Neither the `names_to` nor the `values_to` column exists in `pew`, so we have to put their name in quotes.

## Numeric data in column names {#billboard}

For many datasets, `pivot_longer()` is all you need. But for more complex datasets it often makes sense to manually generate a data frame that precisely describes the transformation. For example, take the billboard data:

```{r}
billboard <- read_csv("billboard.csv", col_types = list(time = col_skip()))
billboard
```

This records the billboard rank of songs over time. It is very similar in form to the `pew` data above, but the data encoded in the column names is really a number, not a string. This means that `pivot_longer()` works, but will require some additional cleaning afterwards:

```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    values_to = "rank",
    na.rm = TRUE
  )
```

Instead of doing that cleaning on the long data, we can tackle the problem in another way: by generating a pivot spec. (Using a pivoting spec is probably overkill for this problem, but it's a good bridge between very simple cases and the more complex cases you'll learn about shortly.) A pivoting spec is a data frame that describes the metadata stored in the column name, with one row for each column, and one column for each variable mashed into the column name. 

We start using `pivot_longer_spec()` to generate the spec that `pivot_longer()` generates behind the scenes:

```{r}
spec <- billboard %>% 
  pivot_longer_spec(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    values_to = "rank"
  )
spec
```

The spec is a data frame with one row for each column, and two special columns that start with `.`:

* `.name` gives the name of the column.
* `.value` gives the name of the column that the values in the cells will
  go into.
  
All other variables are maintained in the output of the pivot.

To make this spec a more accurate rendition of the metadata that's stored in the column names, we need to turn the string into an integer:

```{r}
spec <- spec %>% 
  mutate(week = as.integer(week))
spec
```

We can now provide this spec to `pivot_longer()`:

```{r}
billboard %>% 
  pivot_longer(spec = spec)
```

This seems like a lot of work to get something very similar to the previous result, but as you'll see shortly, it generalises in very useful ways.

The pivotting spec allows us to be more precise about exactly how `pivot_longer(df, spec = spec)` changes the shape of `df`: it will have `nrow(df) * nrow(spec)` rows, and `ncol(df) - nrow(spec) + ncol(spec) - 2` columns.

## Multiple value columns 

So far the `.value` column has only ever contained a single value, so you might wonder why we need it. In fact, `.value` is very important as it allows us to solve a problem that was previously very challenging with `spread()`. Multiple values of `.value` allows us access to a new feature inspired by data.table: you can gather columns with different types. The following example is adapted from the [data.table vignette](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html):

```{r}
family <- tibble::tribble(
  ~family,  ~dob_child1,  ~dob_child2, ~gender_child1, ~gender_child2,
       1L, "1998-11-26", "2000-01-29",             1L,             2L,
       2L, "1996-06-22",           NA,             2L,             NA,
       3L, "2002-07-11", "2004-04-05",             2L,             2L,
       4L, "2004-10-10", "2009-08-27",             1L,             1L,
       5L, "2000-12-05", "2005-02-28",             2L,             1L,
)
family <- family %>% mutate_at(vars(starts_with("dob")), parse_date)
family
```

Note that we have two pieces of information about each child: their gender and their date of birth. These need to go into separate columns in the result. We can do this by suppling multiple elements to `names_to`, where `.value` is a special sentinel that represent the value column in the output.

```{r}
family %>% 
  pivot_longer(-family, names_to = c(".value", "child"), names_sep = "_", na.rm = TRUE)
```

We use `na.rm = TRUE` here because this shape of the data forces the creation of explicit missing variables for observations that don't exist. This ensures that family 2 has a single row in the output.

Another case of this problem is the built-in `anscombe` dataset:

```{r}
anscombe
```

This dataset contains four pairs of variables (`x1` + `y1`, `x2` + `y2`, etc) that underlie Anscombe's quartet, a collection of four datasets that have the same summary statistics (mean, sd, correlation etc), but have quite different data. We want to produce a dataset with columns `graph`, `x` and `y`. 

```{r}
anscombe %>% 
  pivot_longer(everything(), names_to = c(".value", "graph"), names_sep = 1) %>% 
  arrange(graph)
```

A similar situation can arise with panel data. For example, take this example dataset provided by [Thomas Leeper](http://github.com/leeper/rio/issues/193):

```{r}
pnl <- tibble(
  x = 1:4,
  a = c(1, 1,0, 0),
  b = c(0, 1, 1, 1),
  y1 = rnorm(4),
  y2 = rnorm(4),
  z1 = rep(3, 4),
  z2 = rep(-2, 4),
)
pnl %>% 
  pivot_longer(-(x:b), names_to = c(".value", "time"), names_sep = 1)
```

## Many variables in column names

In more complex cases, the variables encoded the column names might require more significant parsing to extract. For example, take the `who` dataset bundled with this package:

```{r}
who
```

`country`, `iso2`, `iso3`, and `year` are already variables, so can be left as is. We want to pivot the columns from `new_sp_m014` to `newrel_f65`:

```{r}
spec <- who %>%
  pivot_longer_spec(new_sp_m014:newrel_f65, values_to = "count")
spec
```

These columns encode four variables in their names:

* The `new_`/`new` prefix indicates these are counts of new cases. This
  dataset only contains new cases, so here we'll ignore this variable because 
  it's constant.
  
* `sp`/`rel`/`sp`/`ep` describe how the case was diagnosed.

* `m`/`f` gives the gender.

* `014`/`1524`/`2535`/`3544`/`4554`/`65` supplies the age range.

We can extract these variables out of the `name` using `extract()`:

```{r}
spec <- spec %>%
  extract(name, c("diagnosis", "gender", "age"), "new_?(.*)_(.)(.*)")
spec
```

(Note that `.name` must stay unchanged as it's our index into the column names of the original dataset.)

Gender and age have fixed and known values, so it's good practice to convert these strings to factors:

```{r}
spec <- spec %>%
  mutate(
    gender = factor(gender, levels = c("f", "m")),
    age = factor(age, levels = unique(age), ordered = TRUE)
  )
spec
```

Finally, we can use this spec to tidy the dataset:

```{r}
who %>% pivot_longer(spec = spec)
```

## Manual spec construction

Sometimes it's not possible (or not convenient) to compute the spec from the column names, and instead it can be convenient to construct the spec by hand. For example, take this `construction` data, which is lightly modified from Table 5 "completions" found at <https://www.census.gov/construction/nrc/index.html>:

```{r}
construction <- read_csv("construction.csv", col_types = list("2 to 4 units" = col_integer()))
construction
```

This sort of data is not uncommon from government agencies: the column names actually belong to different variables, and here we have summaries for number of units (1, 2-4, 5+) and regions of the country (NE, NW, midwest, S, W). We can most easily describe that with a tibble:

```{r}
spec <- tribble(
  ~.name,            ~.value, ~units,  ~region,     
  "Total",           "n",     "total", NA,          
  "1 unit",          "n",     "1",     NA,          
  "2 to 4 units",    "n",     "2-4",   NA,          
  "5 units or more", "n",     "5+",    NA,          
  "Northeast",       "n",     NA,      "Northeast", 
  "Midwest",         "n",     NA,      "Midwest",   
  "South",           "n",     NA,      "South",     
  "West",            "n",     NA,      "West",      
)
```

Which yields the following long form:

```{r}
construction %>% pivot_longer(spec = spec)
```

(Note that there is no overlap between the `units` and `region` variables; here the data would really be most naturally described in two independent tables.)

# Long to wide

`pivot_wider()` is the opposite of `pivot_longer()`: it makes a dataset __wider__ by reducing the number of rows and increasing the number of columns. It's relatively rare to need `pivot_wider()` to make tidy data, but it's often useful for creating summary tables for presentation, or data in a format needed by other tools.

Note that it is generally true that `pivot_longer()` and `pivot_wider()` are symmetric: `df %>% pivot_longer(spec = spec) %>% pivot_wider(spec = spec)` and `df %>% pivot_wider(spec = spec) %>% pivot_longer(spec = spec)` will yield `df`.

## Capture-recapture data

The `fish_encounters` dataset, contributed by [Myfanwy Johnston](https://fishsciences.github.io/post/visualizing-fish-encounter-histories/), describes when fish swimming down a river are detected by automatic monitoring stations:

```{r}
fish_encounters
```

Many tools used to analyse this data need it in a form where each station is a column:

```{r}
fish_encounters %>% pivot_wider(names_from = station, values_from = seen)
```

This dataset only records when a fish was detected by the station - it doesn't record when it wasn't detected (this is common with this sort of data). That means the output data is filled with `NA`s. However, in this case we know that the absence of a record means that the fish was not `seen`, so we can ask `pivot_wider()` to fill these missing values in with zeros:

```{r}
fish_encounters %>% pivot_wider(
  names_from = station, 
  values_from = seen,
  values_fill = list(seen = 0)
)
```

## Generate column name from multiple variables

Imagine, as in <http://stackoverflow.com/questions/24929954>, that we have information containing the combination of product, country, and year. In tidy form it might look like this:

```{r}
df <- expand_grid(
    product = c("A", "B"), 
    country = c("AI", "EI"), 
    year = 2000:2014
  ) %>%
  filter((product == "A" & country == "AI") | product == "B") %>% 
  mutate(value = rnorm(nrow(.)))
df
```

We want to widen the data so we have one column for each combination of `product` and `country`. The key is to specify multiple variables for `names_from`:

```{r}
df %>% pivot_wider(names_from = c(product, country), values_from = value)
```

If you want finer control over the generated columns, you can create a spec data frame. This has exactly the same format as for `pivot_longer()`: a data frame with special `.name` and `.value` columns. But when fed to `pivot_wider()` it does the opposite transformation to `pivot_longer()`: it create the columns specified in `.name`, using the information from `.value` and the other columns.

For this dataset, you might want to generate a custom spec if you wanted to ensure that every possible combination of `country` and `product` got it's own column, not just those present in the data:

```{r}
spec <- df %>% 
  expand(product, country, .value = "value") %>% 
  unite(".name", product, country, remove = FALSE)
spec
df %>% pivot_wider(spec = spec) %>% head()
```

## Tidy census

The `us_rent_income` dataset contains information about median income and rent for each state in the US for 2017 (from the American Community Survey, retrieved with the [tidycensus][tidycensus] package).

```{r}
us_rent_income
```

We'd like to generate a dataset with columns `rent`, `rent_moe`, `income`, and `income_moe`.  There are many ways that you could generate this spec, but the key is that we need to generate every combination of the `variable` values and `estimate`/`moe`, and then carefully generate the column name:

```{r}
spec <- us_rent_income %>% 
  expand(variable, .value = c("estimate", "moe")) %>% 
  mutate(
    .name = paste0(variable, ifelse(.value == "moe", "_moe", ""))
  )
spec
```

Supplying this spec to `pivot_wider()` gives us the result we're looking for:

```{r}
us_rent_income %>% pivot_wider(spec = spec)
```

# Other challenges

Sometimes getting a dataset into the needed form requires multiple steps. These final case studies show a few examples that require multiple steps to get them into a useful format.

## World bank

`world_bank_pop` contains data from the World Bank about population per country from 2000 to 2018.

```{r}
world_bank_pop
```

My goal is to produce a tidy dataset where each variable is in a column. It's not obvious exactly what steps are needed yet, but I'll start with the most obvious problem: year is spread across multiple columns.

```{r}
pop2 <- world_bank_pop %>% 
  pivot_longer(`2000`:`2017`, names_to = "year")
pop2
```

Next we need to consider the `indicator` variable:

```{r}
pop2 %>% count(indicator)
```

Here `SP.POP.GROW` is population growth, `SP.POP.TOTL` is total population, and `SP.URB.*` are the same but only for urban areas. Let's split this up into two variables: `area` (total or urban) and the actual variable (population or growth): 

```{r}
pop3 <- pop2 %>% 
  separate(indicator, c(NA, "area", "variable"))
pop3
```

Now we can complete the tidying by pivoting `variable` and `value` to make `TOTL` and `GROW` columns:

```{r}
pop3 %>% 
  pivot_wider(names_from = variable, values_from = value)
```

## Multi-choice

Thanks to Maxime Wack. From <https://github.com/tidyverse/tidyr/issues/384>

```{r}
df <- tibble::tribble(
  ~id, ~choice1, ~choice2, ~choice3,
  1, "A", "B", "C",
  2, "B", "C",  NA,
  3, "D",  NA,  NA,
  4, "B", "D",  NA
)
df %>% 
  pivot_longer(-id, na.rm = TRUE) %>% 
  dplyr::count(id, value) %>% 
  pivot_wider(
    names_from = value, 
    values_from = n, 
    values_fill = list(n = 0)
  )
```


## Contact list

A final challenge is inspired by [Jiena Gu](https://github.com/jienagu/tidyverse_examples/blob/master/example_long_wide.R). Imagine you have a contact list that you've copied and pasted from a website:

```{r}
contacts <- tribble(
  ~field, ~value,
  "name", "Jiena McLellan",
  "company", "Toyota", 
  "name", "John Smith", 
  "company", "google", 
  "email", "john@google.com",
  "name", "Huxley Ratcliffe"
)
```

This is challenging because there's no variable that identifies which observations belong together, and unlike `anscombe` there's no regular pattern. We can fix this by noting that every contact starts with a name, so we can create a unique id by counting every time we see "name" as the `field`: 

```{r}
contacts <- contacts %>% 
  mutate(
    person_id = cumsum(field == "name")
  )
contacts
```

Now that we have a unique identifier for each person, we can pivot `field` and `value` into the columns:

```{r}
contacts %>% 
  pivot_wider(names_from = field, values_from = value)
```

[cdata]: https://winvector.github.io/cdata/
[data.table]: https://github.com/Rdatatable/data.table/wiki
[tidycensus]: https://walkerke.github.io/tidycensus